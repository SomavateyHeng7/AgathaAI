{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 108, "column": 0}, "map": {"version":3,"sources":["file:///Users/teyyyyyheng/Downloads/Archive%204/src/lib/database.ts"],"sourcesContent":["import { Pool, PoolConfig } from 'pg';\n\nconst poolConfig: PoolConfig = {\n  connectionString: process.env.DATABASE_URL,\n  min: parseInt(process.env.DATABASE_POOL_MIN || '2'),\n  max: parseInt(process.env.DATABASE_POOL_MAX || '10'),\n  idleTimeoutMillis: 30000,\n  connectionTimeoutMillis: 2000,\n};\n\n// Create a singleton pool\nlet pool: Pool | null = null;\n\nfunction getPool() {\n  if (!pool) {\n    pool = new Pool(poolConfig);\n    \n    pool.on('error', (err) => {\n      console.error('Unexpected database error:', err);\n    });\n  }\n  \n  return pool;\n}\n\nexport async function query(text: string, params?: any[]) {\n  const pool = getPool();\n  const start = Date.now();\n  \n  try {\n    const res = await pool.query(text, params);\n    const duration = Date.now() - start;\n    \n    if (process.env.NODE_ENV === 'development') {\n      console.log('Executed query', { text: text.substring(0, 100), duration, rows: res.rowCount });\n    }\n    \n    return res;\n  } catch (error) {\n    console.error('Database query error:', error);\n    throw error;\n  }\n}\n\nexport async function getClient() {\n  const pool = getPool();\n  return await pool.connect();\n}\n\nexport async function testConnection() {\n  try {\n    const result = await query('SELECT NOW()');\n    console.log('✅ Database connected:', result.rows[0].now);\n    return true;\n  } catch (error) {\n    console.error('❌ Database connection failed:', error);\n    return false;\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;;;;;;AAEA,MAAM,aAAyB;IAC7B,kBAAkB,QAAQ,GAAG,CAAC,YAAY;IAC1C,KAAK,SAAS,QAAQ,GAAG,CAAC,iBAAiB,IAAI;IAC/C,KAAK,SAAS,QAAQ,GAAG,CAAC,iBAAiB,IAAI;IAC/C,mBAAmB;IACnB,yBAAyB;AAC3B;AAEA,0BAA0B;AAC1B,IAAI,OAAoB;AAExB,SAAS;IACP,IAAI,CAAC,MAAM;QACT,OAAO,IAAI,qJAAI,CAAC;QAEhB,KAAK,EAAE,CAAC,SAAS,CAAC;YAChB,QAAQ,KAAK,CAAC,8BAA8B;QAC9C;IACF;IAEA,OAAO;AACT;AAEO,eAAe,MAAM,IAAY,EAAE,MAAc;IACtD,MAAM,OAAO;IACb,MAAM,QAAQ,KAAK,GAAG;IAEtB,IAAI;QACF,MAAM,MAAM,MAAM,KAAK,KAAK,CAAC,MAAM;QACnC,MAAM,WAAW,KAAK,GAAG,KAAK;QAE9B,wCAA4C;YAC1C,QAAQ,GAAG,CAAC,kBAAkB;gBAAE,MAAM,KAAK,SAAS,CAAC,GAAG;gBAAM;gBAAU,MAAM,IAAI,QAAQ;YAAC;QAC7F;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,MAAM;IACR;AACF;AAEO,eAAe;IACpB,MAAM,OAAO;IACb,OAAO,MAAM,KAAK,OAAO;AAC3B;AAEO,eAAe;IACpB,IAAI;QACF,MAAM,SAAS,MAAM,MAAM;QAC3B,QAAQ,GAAG,CAAC,yBAAyB,OAAO,IAAI,CAAC,EAAE,CAAC,GAAG;QACvD,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,iCAAiC;QAC/C,OAAO;IACT;AACF"}},
    {"offset": {"line": 180, "column": 0}, "map": {"version":3,"sources":["file:///Users/teyyyyyheng/Downloads/Archive%204/src/lib/auth-config.ts"],"sourcesContent":["import type { NextAuthOptions } from \"next-auth\";\nimport GoogleProvider from \"next-auth/providers/google\";\nimport CredentialsProvider from \"next-auth/providers/credentials\";\nimport { query } from \"./database\";\nimport bcrypt from \"bcrypt\";\n\nexport const authOptions: NextAuthOptions = {\n  providers: [\n    GoogleProvider({\n      clientId: process.env.GOOGLE_CLIENT_ID || \"\",\n      clientSecret: process.env.GOOGLE_CLIENT_SECRET || \"\",\n    }),\n    CredentialsProvider({\n      name: \"Credentials\",\n      credentials: {\n        email: { label: \"Email\", type: \"email\" },\n        password: { label: \"Password\", type: \"password\" },\n      },\n      async authorize(credentials) {\n        if (!credentials?.email || !credentials?.password) {\n          return null;\n        }\n\n        try {\n          // Get user from database\n          const result = await query(\"SELECT * FROM users WHERE email = $1\", [\n            credentials.email as string,\n          ]);\n\n          if (result.rows.length === 0) {\n            return null;\n          }\n\n          const user = result.rows[0];\n\n          // Verify password\n          const isValid = await bcrypt.compare(\n            credentials.password as string,\n            user.password_hash,\n          );\n\n          if (!isValid) {\n            return null;\n          }\n\n          // Get user's API key\n          const apiKeyResult = await query(\n            \"SELECT key_hash FROM api_keys WHERE user_id = $1 AND status = 'active' LIMIT 1\",\n            [user.id],\n          );\n\n          return {\n            id: user.id,\n            email: user.email,\n            name: user.full_name,\n            tier: user.subscription_tier,\n            apiKey: apiKeyResult.rows[0]?.key_hash || null,\n          };\n        } catch (error) {\n          console.error(\"Auth error:\", error);\n          return null;\n        }\n      },\n    }),\n  ],\n  callbacks: {\n    async signIn({ user, account }) {\n      if (account?.provider === \"google\") {\n        try {\n          // Validate required fields from Google\n          if (!user.email) {\n            console.error(\n              \"Google sign-in error: Missing email from Google profile\",\n            );\n            return false;\n          }\n\n          // Check if user exists\n          const existingUser = await query(\n            \"SELECT * FROM users WHERE email = $1\",\n            [user.email],\n          );\n\n          if (existingUser.rows.length === 0) {\n            // Create new user\n            console.log(\"Creating new user:\", user.email);\n            const newUser = await query(\n              `INSERT INTO users (email, full_name, subscription_tier, email_verified, password_hash, created_at)\n               VALUES ($1, $2, $3, true, '', NOW())\n               RETURNING id`,\n              [user.email, user.name || user.email, \"free\"],\n            );\n\n            const userId = newUser.rows[0].id;\n            console.log(\"User created with ID:\", userId);\n\n            // Generate API key\n            const apiKey = `ak_${Math.random().toString(36).substring(2, 15)}${Math.random().toString(36).substring(2, 15)}`;\n            const keyHash = await bcrypt.hash(apiKey, 10);\n            const keyPrefix = apiKey.substring(0, 8);\n            const keySuffix = apiKey.substring(apiKey.length - 4);\n\n            await query(\n              `INSERT INTO api_keys (user_id, key_hash, key_prefix, key_suffix, name, created_at)\n               VALUES ($1, $2, $3, $4, $5, NOW())`,\n              [userId, keyHash, keyPrefix, keySuffix, \"Default API Key\"],\n            );\n\n            user.id = userId;\n          } else {\n            console.log(\"Existing user found:\", user.email);\n            user.id = existingUser.rows[0].id;\n          }\n\n          return true;\n        } catch (error) {\n          console.error(\"Google sign-in error:\", error);\n          console.error(\"Error details:\", JSON.stringify(error, null, 2));\n          return false;\n        }\n      }\n\n      return true;\n    },\n    async jwt({ token, user, account }) {\n      if (user) {\n        token.id = user.id;\n        token.tier = (user as any).tier;\n        token.apiKey = (user as any).apiKey;\n      }\n\n      if (account?.provider === \"google\" && token.email) {\n        // Get user data from database\n        const result = await query(\n          \"SELECT id, subscription_tier FROM users WHERE email = $1\",\n          [token.email],\n        );\n\n        if (result.rows.length > 0) {\n          token.id = result.rows[0].id;\n          token.tier = result.rows[0].subscription_tier;\n\n          // Get API key\n          const apiKeyResult = await query(\n            \"SELECT key_hash FROM api_keys WHERE user_id = $1 AND status = 'active' LIMIT 1\",\n            [result.rows[0].id],\n          );\n\n          token.apiKey = apiKeyResult.rows[0]?.key_hash || null;\n        }\n      }\n\n      return token;\n    },\n    async session({ session, token }) {\n      if (session.user) {\n        (session.user as any).id = token.id as string;\n        (session.user as any).tier = token.tier as string;\n        (session.user as any).apiKey = token.apiKey as string;\n      }\n      return session;\n    },\n  },\n  pages: {\n    signIn: \"/signin\",\n    signOut: \"/signin\",\n    error: \"/signin\",\n  },\n  session: {\n    strategy: \"jwt\",\n    maxAge: 30 * 24 * 60 * 60, // 30 days\n  },\n  secret: process.env.NEXTAUTH_SECRET,\n};\n"],"names":[],"mappings":";;;;AACA;AACA;AACA;AACA;;;;;;;;;AAEO,MAAM,cAA+B;IAC1C,WAAW;QACT,IAAA,gKAAc,EAAC;YACb,UAAU,QAAQ,GAAG,CAAC,gBAAgB,IAAI;YAC1C,cAAc,QAAQ,GAAG,CAAC,oBAAoB,IAAI;QACpD;QACA,IAAA,qKAAmB,EAAC;YAClB,MAAM;YACN,aAAa;gBACX,OAAO;oBAAE,OAAO;oBAAS,MAAM;gBAAQ;gBACvC,UAAU;oBAAE,OAAO;oBAAY,MAAM;gBAAW;YAClD;YACA,MAAM,WAAU,WAAW;gBACzB,IAAI,CAAC,aAAa,SAAS,CAAC,aAAa,UAAU;oBACjD,OAAO;gBACT;gBAEA,IAAI;oBACF,yBAAyB;oBACzB,MAAM,SAAS,MAAM,IAAA,iIAAK,EAAC,wCAAwC;wBACjE,YAAY,KAAK;qBAClB;oBAED,IAAI,OAAO,IAAI,CAAC,MAAM,KAAK,GAAG;wBAC5B,OAAO;oBACT;oBAEA,MAAM,OAAO,OAAO,IAAI,CAAC,EAAE;oBAE3B,kBAAkB;oBAClB,MAAM,UAAU,MAAM,6JAAM,CAAC,OAAO,CAClC,YAAY,QAAQ,EACpB,KAAK,aAAa;oBAGpB,IAAI,CAAC,SAAS;wBACZ,OAAO;oBACT;oBAEA,qBAAqB;oBACrB,MAAM,eAAe,MAAM,IAAA,iIAAK,EAC9B,kFACA;wBAAC,KAAK,EAAE;qBAAC;oBAGX,OAAO;wBACL,IAAI,KAAK,EAAE;wBACX,OAAO,KAAK,KAAK;wBACjB,MAAM,KAAK,SAAS;wBACpB,MAAM,KAAK,iBAAiB;wBAC5B,QAAQ,aAAa,IAAI,CAAC,EAAE,EAAE,YAAY;oBAC5C;gBACF,EAAE,OAAO,OAAO;oBACd,QAAQ,KAAK,CAAC,eAAe;oBAC7B,OAAO;gBACT;YACF;QACF;KACD;IACD,WAAW;QACT,MAAM,QAAO,EAAE,IAAI,EAAE,OAAO,EAAE;YAC5B,IAAI,SAAS,aAAa,UAAU;gBAClC,IAAI;oBACF,uCAAuC;oBACvC,IAAI,CAAC,KAAK,KAAK,EAAE;wBACf,QAAQ,KAAK,CACX;wBAEF,OAAO;oBACT;oBAEA,uBAAuB;oBACvB,MAAM,eAAe,MAAM,IAAA,iIAAK,EAC9B,wCACA;wBAAC,KAAK,KAAK;qBAAC;oBAGd,IAAI,aAAa,IAAI,CAAC,MAAM,KAAK,GAAG;wBAClC,kBAAkB;wBAClB,QAAQ,GAAG,CAAC,sBAAsB,KAAK,KAAK;wBAC5C,MAAM,UAAU,MAAM,IAAA,iIAAK,EACzB,CAAC;;2BAEY,CAAC,EACd;4BAAC,KAAK,KAAK;4BAAE,KAAK,IAAI,IAAI,KAAK,KAAK;4BAAE;yBAAO;wBAG/C,MAAM,SAAS,QAAQ,IAAI,CAAC,EAAE,CAAC,EAAE;wBACjC,QAAQ,GAAG,CAAC,yBAAyB;wBAErC,mBAAmB;wBACnB,MAAM,SAAS,CAAC,GAAG,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,GAAG,MAAM,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,SAAS,CAAC,GAAG,KAAK;wBAChH,MAAM,UAAU,MAAM,6JAAM,CAAC,IAAI,CAAC,QAAQ;wBAC1C,MAAM,YAAY,OAAO,SAAS,CAAC,GAAG;wBACtC,MAAM,YAAY,OAAO,SAAS,CAAC,OAAO,MAAM,GAAG;wBAEnD,MAAM,IAAA,iIAAK,EACT,CAAC;iDACkC,CAAC,EACpC;4BAAC;4BAAQ;4BAAS;4BAAW;4BAAW;yBAAkB;wBAG5D,KAAK,EAAE,GAAG;oBACZ,OAAO;wBACL,QAAQ,GAAG,CAAC,wBAAwB,KAAK,KAAK;wBAC9C,KAAK,EAAE,GAAG,aAAa,IAAI,CAAC,EAAE,CAAC,EAAE;oBACnC;oBAEA,OAAO;gBACT,EAAE,OAAO,OAAO;oBACd,QAAQ,KAAK,CAAC,yBAAyB;oBACvC,QAAQ,KAAK,CAAC,kBAAkB,KAAK,SAAS,CAAC,OAAO,MAAM;oBAC5D,OAAO;gBACT;YACF;YAEA,OAAO;QACT;QACA,MAAM,KAAI,EAAE,KAAK,EAAE,IAAI,EAAE,OAAO,EAAE;YAChC,IAAI,MAAM;gBACR,MAAM,EAAE,GAAG,KAAK,EAAE;gBAClB,MAAM,IAAI,GAAG,AAAC,KAAa,IAAI;gBAC/B,MAAM,MAAM,GAAG,AAAC,KAAa,MAAM;YACrC;YAEA,IAAI,SAAS,aAAa,YAAY,MAAM,KAAK,EAAE;gBACjD,8BAA8B;gBAC9B,MAAM,SAAS,MAAM,IAAA,iIAAK,EACxB,4DACA;oBAAC,MAAM,KAAK;iBAAC;gBAGf,IAAI,OAAO,IAAI,CAAC,MAAM,GAAG,GAAG;oBAC1B,MAAM,EAAE,GAAG,OAAO,IAAI,CAAC,EAAE,CAAC,EAAE;oBAC5B,MAAM,IAAI,GAAG,OAAO,IAAI,CAAC,EAAE,CAAC,iBAAiB;oBAE7C,cAAc;oBACd,MAAM,eAAe,MAAM,IAAA,iIAAK,EAC9B,kFACA;wBAAC,OAAO,IAAI,CAAC,EAAE,CAAC,EAAE;qBAAC;oBAGrB,MAAM,MAAM,GAAG,aAAa,IAAI,CAAC,EAAE,EAAE,YAAY;gBACnD;YACF;YAEA,OAAO;QACT;QACA,MAAM,SAAQ,EAAE,OAAO,EAAE,KAAK,EAAE;YAC9B,IAAI,QAAQ,IAAI,EAAE;gBACf,QAAQ,IAAI,CAAS,EAAE,GAAG,MAAM,EAAE;gBAClC,QAAQ,IAAI,CAAS,IAAI,GAAG,MAAM,IAAI;gBACtC,QAAQ,IAAI,CAAS,MAAM,GAAG,MAAM,MAAM;YAC7C;YACA,OAAO;QACT;IACF;IACA,OAAO;QACL,QAAQ;QACR,SAAS;QACT,OAAO;IACT;IACA,SAAS;QACP,UAAU;QACV,QAAQ,KAAK,KAAK,KAAK;IACzB;IACA,QAAQ,QAAQ,GAAG,CAAC,eAAe;AACrC"}},
    {"offset": {"line": 382, "column": 0}, "map": {"version":3,"sources":["file:///Users/teyyyyyheng/Downloads/Archive%204/src/lib/llm.ts"],"sourcesContent":["import OpenAI from \"openai\";\nimport { GoogleGenerativeAI } from \"@google/generative-ai\";\nimport { query } from \"./database\";\n\nconst openai = process.env.OPENAI_API_KEY\n  ? new OpenAI({ apiKey: process.env.OPENAI_API_KEY })\n  : null;\nconst gemini = process.env.GEMINI_API_KEY\n  ? new GoogleGenerativeAI(process.env.GEMINI_API_KEY)\n  : null;\n\ninterface InferenceParams {\n  temperature?: number;\n  maxTokens?: number;\n  topP?: number;\n}\n\nexport async function processInference(\n  requestId: string,\n  userId: string,\n  model: string,\n  prompt: string,\n  parameters: InferenceParams,\n) {\n  const startTime = Date.now();\n\n  try {\n    // Update status to processing\n    await query(\"UPDATE inference_requests SET status = $1 WHERE id = $2\", [\n      \"processing\",\n      requestId,\n    ]);\n\n    let response: string;\n    let tokensPrompt: number;\n    let tokensCompletion: number;\n\n    // Call appropriate LLM provider\n    if (model.startsWith(\"gpt-\")) {\n      if (!openai) throw new Error(\"OpenAI API key not configured\");\n      const result = await callOpenAI(model, prompt, parameters);\n      response = result.response;\n      tokensPrompt = result.tokensPrompt;\n      tokensCompletion = result.tokensCompletion;\n    } else if (model.startsWith(\"gemini-\")) {\n      if (!gemini) throw new Error(\"Gemini API key not configured\");\n      const result = await callGemini(model, prompt, parameters);\n      response = result.response;\n      tokensPrompt = result.tokensPrompt;\n      tokensCompletion = result.tokensCompletion;\n    } else {\n      throw new Error(`Unsupported model: ${model}`);\n    }\n\n    const processingTime = Date.now() - startTime;\n    const tokensTotal = tokensPrompt + tokensCompletion;\n\n    // Update request with results\n    await query(\n      `UPDATE inference_requests\n       SET status = $1, response = $2, tokens_prompt = $3, tokens_completion = $4,\n           tokens_total = $5, processing_time_ms = $6, completed_at = NOW()\n       WHERE id = $7`,\n      [\n        \"completed\",\n        response,\n        tokensPrompt,\n        tokensCompletion,\n        tokensTotal,\n        processingTime,\n        requestId,\n      ],\n    );\n\n    // Update usage statistics\n    await updateUsageStatistics(userId, tokensTotal, processingTime, model);\n  } catch (error: any) {\n    console.error(\"Inference processing error:\", error);\n\n    await query(\n      `UPDATE inference_requests\n       SET status = $1, error_message = $2, completed_at = NOW()\n       WHERE id = $3`,\n      [\"failed\", error.message, requestId],\n    );\n  }\n}\n\nasync function callOpenAI(\n  model: string,\n  prompt: string,\n  params: InferenceParams,\n) {\n  const completion = await openai!.chat.completions.create({\n    model,\n    messages: [{ role: \"user\", content: prompt }],\n    temperature: params.temperature || 0.7,\n    max_tokens: params.maxTokens || 1000,\n    top_p: params.topP || 1,\n  });\n\n  return {\n    response: completion.choices[0].message.content || \"\",\n    tokensPrompt: completion.usage?.prompt_tokens || 0,\n    tokensCompletion: completion.usage?.completion_tokens || 0,\n  };\n}\n\nasync function callGemini(\n  model: string,\n  prompt: string,\n  params: InferenceParams,\n) {\n  // Map model names to actual Gemini model IDs\n  const modelMap: Record<string, string> = {\n    \"gemini-pro\": \"gemini-1.5-flash-8b\",\n    \"gemini-1.5-pro\": \"gemini-1.5-flash-8b\",\n    \"gemini-1.5-flash\": \"gemini-1.5-flash-8b\",\n  };\n\n  const actualModel = modelMap[model] || \"gemini-1.5-flash-8b\";\n  const genModel = gemini!.getGenerativeModel({ model: actualModel });\n\n  const result = await genModel.generateContent({\n    contents: [{ role: \"user\", parts: [{ text: prompt }] }],\n    generationConfig: {\n      temperature: params.temperature || 0.7,\n      maxOutputTokens: params.maxTokens || 1000,\n      topP: params.topP || 1,\n    },\n  });\n\n  const response = result.response;\n  const text = response.text();\n\n  const tokensPrompt =\n    response.usageMetadata?.promptTokenCount || Math.ceil(prompt.length / 4);\n  const tokensCompletion =\n    response.usageMetadata?.candidatesTokenCount || Math.ceil(text.length / 4);\n\n  return {\n    response: text,\n    tokensPrompt,\n    tokensCompletion,\n  };\n}\nasync function updateUsageStatistics(\n  userId: string,\n  tokens: number,\n  processingTime: number,\n  model: string,\n) {\n  const today = new Date().toISOString().split(\"T\")[0];\n\n  await query(\n    `INSERT INTO usage_statistics (user_id, date, total_requests, successful_requests, total_tokens, avg_response_time_ms, models_used)\n     VALUES ($1, $2, 1, 1, $3, $4, $5)\n     ON CONFLICT (user_id, date)\n     DO UPDATE SET\n       total_requests = usage_statistics.total_requests + 1,\n       successful_requests = usage_statistics.successful_requests + 1,\n       total_tokens = usage_statistics.total_tokens + $3,\n       avg_response_time_ms = (usage_statistics.avg_response_time_ms * usage_statistics.total_requests + $4) / (usage_statistics.total_requests + 1),\n       models_used = usage_statistics.models_used || $5`,\n    [userId, today, tokens, processingTime, JSON.stringify({ [model]: 1 })],\n  );\n}\n\nexport async function chat(\n  model: string,\n  messages: Array<{ role: string; content: string }>,\n  params: InferenceParams = {},\n) {\n  const startTime = Date.now();\n\n  let response: string;\n  let tokensPrompt: number;\n  let tokensCompletion: number;\n\n  if (model.startsWith(\"gpt-\")) {\n    if (!openai) throw new Error(\"OpenAI API key not configured\");\n    const result = await callOpenAIChat(model, messages, params);\n    response = result.response;\n    tokensPrompt = result.tokensPrompt;\n    tokensCompletion = result.tokensCompletion;\n  } else if (model.startsWith(\"gemini-\")) {\n    if (!gemini) throw new Error(\"Gemini API key not configured\");\n    const result = await callGeminiChat(model, messages, params);\n    response = result.response;\n    tokensPrompt = result.tokensPrompt;\n    tokensCompletion = result.tokensCompletion;\n  } else {\n    throw new Error(`Unsupported model: ${model}`);\n  }\n\n  const processingTime = Date.now() - startTime;\n\n  return {\n    response,\n    tokensPrompt,\n    tokensCompletion,\n    tokensTotal: tokensPrompt + tokensCompletion,\n    processingTime,\n  };\n}\n\nasync function callOpenAIChat(\n  model: string,\n  messages: Array<{ role: string; content: string }>,\n  params: InferenceParams,\n) {\n  const completion = await openai!.chat.completions.create({\n    model,\n    messages: messages as any,\n    temperature: params.temperature || 0.7,\n    max_tokens: params.maxTokens || 2000,\n    top_p: params.topP || 1,\n  });\n\n  return {\n    response: completion.choices[0].message.content || \"\",\n    tokensPrompt: completion.usage?.prompt_tokens || 0,\n    tokensCompletion: completion.usage?.completion_tokens || 0,\n  };\n}\n\nasync function callGeminiChat(\n  model: string,\n  messages: Array<{ role: string; content: string }>,\n  params: InferenceParams,\n) {\n  const modelMap: Record<string, string> = {\n    \"gemini-pro\": \"gemini-1.5-flash\",\n    \"gemini-2.5-flash\": \"gemini-2.5-flash\",\n    \"gemini-2.0-flash\": \"gemini-2.0-flash\",\n  };\n\n  const actualModel = modelMap[model] || \"gemini-2.0-flash\";\n  const genModel = gemini!.getGenerativeModel({ model: actualModel });\n\n  const contents = messages.map((msg) => ({\n    role: msg.role === \"assistant\" ? \"model\" : \"user\",\n    parts: [{ text: msg.content }],\n  }));\n\n  const result = await genModel.generateContent({\n    contents,\n    generationConfig: {\n      temperature: params.temperature || 0.7,\n      maxOutputTokens: params.maxTokens || 2000,\n      topP: params.topP || 1,\n    },\n  });\n\n  const responseObj = result.response;\n  const text = responseObj.text();\n\n  const tokensPrompt =\n    responseObj.usageMetadata?.promptTokenCount ||\n    Math.ceil(messages.reduce((sum, m) => sum + m.content.length, 0) / 4);\n  const tokensCompletion =\n    responseObj.usageMetadata?.candidatesTokenCount ||\n    Math.ceil(text.length / 4);\n\n  return {\n    response: text,\n    tokensPrompt,\n    tokensCompletion,\n  };\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;;;;;AAEA,MAAM,SAAS,QAAQ,GAAG,CAAC,cAAc,GACrC,IAAI,6JAAM,CAAC;IAAE,QAAQ,QAAQ,GAAG,CAAC,cAAc;AAAC,KAChD;AACJ,MAAM,SAAS,QAAQ,GAAG,CAAC,cAAc,GACrC,IAAI,sLAAkB,CAAC,QAAQ,GAAG,CAAC,cAAc,IACjD;AAQG,eAAe,iBACpB,SAAiB,EACjB,MAAc,EACd,KAAa,EACb,MAAc,EACd,UAA2B;IAE3B,MAAM,YAAY,KAAK,GAAG;IAE1B,IAAI;QACF,8BAA8B;QAC9B,MAAM,IAAA,iIAAK,EAAC,2DAA2D;YACrE;YACA;SACD;QAED,IAAI;QACJ,IAAI;QACJ,IAAI;QAEJ,gCAAgC;QAChC,IAAI,MAAM,UAAU,CAAC,SAAS;YAC5B,IAAI,CAAC,QAAQ,MAAM,IAAI,MAAM;YAC7B,MAAM,SAAS,MAAM,WAAW,OAAO,QAAQ;YAC/C,WAAW,OAAO,QAAQ;YAC1B,eAAe,OAAO,YAAY;YAClC,mBAAmB,OAAO,gBAAgB;QAC5C,OAAO,IAAI,MAAM,UAAU,CAAC,YAAY;YACtC,IAAI,CAAC,QAAQ,MAAM,IAAI,MAAM;YAC7B,MAAM,SAAS,MAAM,WAAW,OAAO,QAAQ;YAC/C,WAAW,OAAO,QAAQ;YAC1B,eAAe,OAAO,YAAY;YAClC,mBAAmB,OAAO,gBAAgB;QAC5C,OAAO;YACL,MAAM,IAAI,MAAM,CAAC,mBAAmB,EAAE,OAAO;QAC/C;QAEA,MAAM,iBAAiB,KAAK,GAAG,KAAK;QACpC,MAAM,cAAc,eAAe;QAEnC,8BAA8B;QAC9B,MAAM,IAAA,iIAAK,EACT,CAAC;;;oBAGa,CAAC,EACf;YACE;YACA;YACA;YACA;YACA;YACA;YACA;SACD;QAGH,0BAA0B;QAC1B,MAAM,sBAAsB,QAAQ,aAAa,gBAAgB;IACnE,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,+BAA+B;QAE7C,MAAM,IAAA,iIAAK,EACT,CAAC;;oBAEa,CAAC,EACf;YAAC;YAAU,MAAM,OAAO;YAAE;SAAU;IAExC;AACF;AAEA,eAAe,WACb,KAAa,EACb,MAAc,EACd,MAAuB;IAEvB,MAAM,aAAa,MAAM,OAAQ,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;QACvD;QACA,UAAU;YAAC;gBAAE,MAAM;gBAAQ,SAAS;YAAO;SAAE;QAC7C,aAAa,OAAO,WAAW,IAAI;QACnC,YAAY,OAAO,SAAS,IAAI;QAChC,OAAO,OAAO,IAAI,IAAI;IACxB;IAEA,OAAO;QACL,UAAU,WAAW,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,IAAI;QACnD,cAAc,WAAW,KAAK,EAAE,iBAAiB;QACjD,kBAAkB,WAAW,KAAK,EAAE,qBAAqB;IAC3D;AACF;AAEA,eAAe,WACb,KAAa,EACb,MAAc,EACd,MAAuB;IAEvB,6CAA6C;IAC7C,MAAM,WAAmC;QACvC,cAAc;QACd,kBAAkB;QAClB,oBAAoB;IACtB;IAEA,MAAM,cAAc,QAAQ,CAAC,MAAM,IAAI;IACvC,MAAM,WAAW,OAAQ,kBAAkB,CAAC;QAAE,OAAO;IAAY;IAEjE,MAAM,SAAS,MAAM,SAAS,eAAe,CAAC;QAC5C,UAAU;YAAC;gBAAE,MAAM;gBAAQ,OAAO;oBAAC;wBAAE,MAAM;oBAAO;iBAAE;YAAC;SAAE;QACvD,kBAAkB;YAChB,aAAa,OAAO,WAAW,IAAI;YACnC,iBAAiB,OAAO,SAAS,IAAI;YACrC,MAAM,OAAO,IAAI,IAAI;QACvB;IACF;IAEA,MAAM,WAAW,OAAO,QAAQ;IAChC,MAAM,OAAO,SAAS,IAAI;IAE1B,MAAM,eACJ,SAAS,aAAa,EAAE,oBAAoB,KAAK,IAAI,CAAC,OAAO,MAAM,GAAG;IACxE,MAAM,mBACJ,SAAS,aAAa,EAAE,wBAAwB,KAAK,IAAI,CAAC,KAAK,MAAM,GAAG;IAE1E,OAAO;QACL,UAAU;QACV;QACA;IACF;AACF;AACA,eAAe,sBACb,MAAc,EACd,MAAc,EACd,cAAsB,EACtB,KAAa;IAEb,MAAM,QAAQ,IAAI,OAAO,WAAW,GAAG,KAAK,CAAC,IAAI,CAAC,EAAE;IAEpD,MAAM,IAAA,iIAAK,EACT,CAAC;;;;;;;;uDAQkD,CAAC,EACpD;QAAC;QAAQ;QAAO;QAAQ;QAAgB,KAAK,SAAS,CAAC;YAAE,CAAC,MAAM,EAAE;QAAE;KAAG;AAE3E;AAEO,eAAe,KACpB,KAAa,EACb,QAAkD,EAClD,SAA0B,CAAC,CAAC;IAE5B,MAAM,YAAY,KAAK,GAAG;IAE1B,IAAI;IACJ,IAAI;IACJ,IAAI;IAEJ,IAAI,MAAM,UAAU,CAAC,SAAS;QAC5B,IAAI,CAAC,QAAQ,MAAM,IAAI,MAAM;QAC7B,MAAM,SAAS,MAAM,eAAe,OAAO,UAAU;QACrD,WAAW,OAAO,QAAQ;QAC1B,eAAe,OAAO,YAAY;QAClC,mBAAmB,OAAO,gBAAgB;IAC5C,OAAO,IAAI,MAAM,UAAU,CAAC,YAAY;QACtC,IAAI,CAAC,QAAQ,MAAM,IAAI,MAAM;QAC7B,MAAM,SAAS,MAAM,eAAe,OAAO,UAAU;QACrD,WAAW,OAAO,QAAQ;QAC1B,eAAe,OAAO,YAAY;QAClC,mBAAmB,OAAO,gBAAgB;IAC5C,OAAO;QACL,MAAM,IAAI,MAAM,CAAC,mBAAmB,EAAE,OAAO;IAC/C;IAEA,MAAM,iBAAiB,KAAK,GAAG,KAAK;IAEpC,OAAO;QACL;QACA;QACA;QACA,aAAa,eAAe;QAC5B;IACF;AACF;AAEA,eAAe,eACb,KAAa,EACb,QAAkD,EAClD,MAAuB;IAEvB,MAAM,aAAa,MAAM,OAAQ,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;QACvD;QACA,UAAU;QACV,aAAa,OAAO,WAAW,IAAI;QACnC,YAAY,OAAO,SAAS,IAAI;QAChC,OAAO,OAAO,IAAI,IAAI;IACxB;IAEA,OAAO;QACL,UAAU,WAAW,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,IAAI;QACnD,cAAc,WAAW,KAAK,EAAE,iBAAiB;QACjD,kBAAkB,WAAW,KAAK,EAAE,qBAAqB;IAC3D;AACF;AAEA,eAAe,eACb,KAAa,EACb,QAAkD,EAClD,MAAuB;IAEvB,MAAM,WAAmC;QACvC,cAAc;QACd,oBAAoB;QACpB,oBAAoB;IACtB;IAEA,MAAM,cAAc,QAAQ,CAAC,MAAM,IAAI;IACvC,MAAM,WAAW,OAAQ,kBAAkB,CAAC;QAAE,OAAO;IAAY;IAEjE,MAAM,WAAW,SAAS,GAAG,CAAC,CAAC,MAAQ,CAAC;YACtC,MAAM,IAAI,IAAI,KAAK,cAAc,UAAU;YAC3C,OAAO;gBAAC;oBAAE,MAAM,IAAI,OAAO;gBAAC;aAAE;QAChC,CAAC;IAED,MAAM,SAAS,MAAM,SAAS,eAAe,CAAC;QAC5C;QACA,kBAAkB;YAChB,aAAa,OAAO,WAAW,IAAI;YACnC,iBAAiB,OAAO,SAAS,IAAI;YACrC,MAAM,OAAO,IAAI,IAAI;QACvB;IACF;IAEA,MAAM,cAAc,OAAO,QAAQ;IACnC,MAAM,OAAO,YAAY,IAAI;IAE7B,MAAM,eACJ,YAAY,aAAa,EAAE,oBAC3B,KAAK,IAAI,CAAC,SAAS,MAAM,CAAC,CAAC,KAAK,IAAM,MAAM,EAAE,OAAO,CAAC,MAAM,EAAE,KAAK;IACrE,MAAM,mBACJ,YAAY,aAAa,EAAE,wBAC3B,KAAK,IAAI,CAAC,KAAK,MAAM,GAAG;IAE1B,OAAO;QACL,UAAU;QACV;QACA;IACF;AACF"}},
    {"offset": {"line": 620, "column": 0}, "map": {"version":3,"sources":["file:///Users/teyyyyyheng/Downloads/Archive%204/src/app/api/chat/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from \"next/server\";\nimport { getServerSession } from \"next-auth\";\nimport { authOptions } from \"@/lib/auth-config\";\nimport { chat } from \"@/lib/llm\";\nimport { query } from \"@/lib/database\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    const session = await getServerSession(authOptions);\n\n    if (!session || !session.user) {\n      return NextResponse.json({ error: \"Unauthorized\" }, { status: 401 });\n    }\n\n    const body = await request.json();\n    const { conversationId, message, model = \"gpt-4\" } = body;\n\n    if (!message || !message.trim()) {\n      return NextResponse.json(\n        { error: \"Message is required\" },\n        { status: 400 },\n      );\n    }\n\n    const userId = (session.user as any).id;\n\n    let convId = conversationId;\n    if (!convId) {\n      const newConv = await query(\n        `INSERT INTO conversations (user_id, title, model, created_at, updated_at)\n         VALUES ($1, $2, $3, NOW(), NOW())\n         RETURNING id`,\n        [userId, message.substring(0, 100), model],\n      );\n      convId = newConv.rows[0].id;\n    }\n\n    const historyResult = await query(\n      `SELECT role, content FROM conversation_messages\n       WHERE conversation_id = $1\n       ORDER BY created_at ASC`,\n      [convId],\n    );\n\n    const messages = [\n      ...historyResult.rows,\n      { role: \"user\", content: message },\n    ];\n\n    await query(\n      `INSERT INTO conversation_messages (conversation_id, role, content, created_at)\n       VALUES ($1, $2, $3, NOW())`,\n      [convId, \"user\", message],\n    );\n\n    const result = await chat(model, messages);\n\n    await query(\n      `INSERT INTO conversation_messages (conversation_id, role, content, model, tokens_prompt, tokens_completion, created_at)\n       VALUES ($1, $2, $3, $4, $5, $6, NOW())`,\n      [\n        convId,\n        \"assistant\",\n        result.response,\n        model,\n        result.tokensPrompt,\n        result.tokensCompletion,\n      ],\n    );\n\n    await query(\n      `UPDATE conversations\n       SET updated_at = NOW(), message_count = message_count + 2, total_tokens = total_tokens + $2\n       WHERE id = $1`,\n      [convId, result.tokensTotal],\n    );\n\n    return NextResponse.json({\n      conversationId: convId,\n      message: result.response,\n      model,\n      tokens: {\n        prompt: result.tokensPrompt,\n        completion: result.tokensCompletion,\n        total: result.tokensTotal,\n      },\n    });\n  } catch (error: any) {\n    console.error(\"Chat API error:\", error);\n    return NextResponse.json(\n      { error: error.message || \"Failed to process chat\" },\n      { status: 500 },\n    );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,UAAU,MAAM,IAAA,2JAAgB,EAAC,6IAAW;QAElD,IAAI,CAAC,WAAW,CAAC,QAAQ,IAAI,EAAE;YAC7B,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAe,GAAG;gBAAE,QAAQ;YAAI;QACpE;QAEA,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,EAAE,cAAc,EAAE,OAAO,EAAE,QAAQ,OAAO,EAAE,GAAG;QAErD,IAAI,CAAC,WAAW,CAAC,QAAQ,IAAI,IAAI;YAC/B,OAAO,gJAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAsB,GAC/B;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,SAAS,AAAC,QAAQ,IAAI,CAAS,EAAE;QAEvC,IAAI,SAAS;QACb,IAAI,CAAC,QAAQ;YACX,MAAM,UAAU,MAAM,IAAA,iIAAK,EACzB,CAAC;;qBAEY,CAAC,EACd;gBAAC;gBAAQ,QAAQ,SAAS,CAAC,GAAG;gBAAM;aAAM;YAE5C,SAAS,QAAQ,IAAI,CAAC,EAAE,CAAC,EAAE;QAC7B;QAEA,MAAM,gBAAgB,MAAM,IAAA,iIAAK,EAC/B,CAAC;;8BAEuB,CAAC,EACzB;YAAC;SAAO;QAGV,MAAM,WAAW;eACZ,cAAc,IAAI;YACrB;gBAAE,MAAM;gBAAQ,SAAS;YAAQ;SAClC;QAED,MAAM,IAAA,iIAAK,EACT,CAAC;iCAC0B,CAAC,EAC5B;YAAC;YAAQ;YAAQ;SAAQ;QAG3B,MAAM,SAAS,MAAM,IAAA,2HAAI,EAAC,OAAO;QAEjC,MAAM,IAAA,iIAAK,EACT,CAAC;6CACsC,CAAC,EACxC;YACE;YACA;YACA,OAAO,QAAQ;YACf;YACA,OAAO,YAAY;YACnB,OAAO,gBAAgB;SACxB;QAGH,MAAM,IAAA,iIAAK,EACT,CAAC;;oBAEa,CAAC,EACf;YAAC;YAAQ,OAAO,WAAW;SAAC;QAG9B,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,gBAAgB;YAChB,SAAS,OAAO,QAAQ;YACxB;YACA,QAAQ;gBACN,QAAQ,OAAO,YAAY;gBAC3B,YAAY,OAAO,gBAAgB;gBACnC,OAAO,OAAO,WAAW;YAC3B;QACF;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,mBAAmB;QACjC,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,OAAO,MAAM,OAAO,IAAI;QAAyB,GACnD;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}